{"cells":[{"metadata":{"_uuid":"f919d10e2ae012ae8d1c3fc1d81fe46452686609"},"cell_type":"markdown","source":"# House prices\n\n## Todo\n\n* Feature scaling\n* Graphing\n    * Try libraries like `seaborn`, `matplotlib`\n* Better analysis methods\n* (?) Use built-in pipeline CV rather than splitting manually\n    * Hope this cuts down code complexity (slightly)\n    * What graphs does this allow me to make?\n* Backup this kernel on Github\n    * Use the [Kaggle API](https://github.com/Kaggle/kaggle-api) tool to edit locally & run against remote images"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# Imports\n\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import train_test_split\nfrom category_encoders import OneHotEncoder\nfrom xgboost.sklearn import XGBRegressor\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"289e6c5e68ba126fd0a5569dbd24a6d4960b0e0d"},"cell_type":"code","source":"# Load data\n\nrandom_state=3\ninitial_data = pd.read_csv(\"../input/train.csv\")\ntest_data = pd.read_csv(\"../input/test.csv\")\n\n# Align (unencoded) categoricals \ncategory_names = ['MSSubClass', 'MSZoning', 'Street',\n       'Alley', 'LotShape', 'LandContour', 'Utilities', 'LotConfig',\n       'LandSlope', 'Neighborhood', 'Condition1', 'Condition2', 'BldgType',\n       'HouseStyle', 'OverallQual', 'OverallCond',\n       'RoofStyle', 'RoofMatl', 'Exterior1st', 'Exterior2nd',\n       'MasVnrType', 'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual',\n       'BsmtCond', 'BsmtExposure', 'BsmtFinType1',\n       'BsmtFinType2', 'Heating',\n       'HeatingQC', 'CentralAir', 'Electrical', 'KitchenQual',\n       'Functional', 'FireplaceQu', 'GarageType',\n       'GarageFinish', 'GarageQual',\n       'GarageCond', 'PavedDrive', 'PoolQC',\n       'Fence', 'MiscFeature']\nfor category_name in category_names:\n    all_data = pd.concat([initial_data[category_name], test_data[category_name]])\n    categories = pd.Series(all_data, dtype=\"category\")\n    initial_data[category_name] = initial_data[category_name].astype('category', categories)\n    test_data[category_name] = test_data[category_name].astype('category', categories)\n\n# Unnest DataFrames\ninitial_data[category_names] = initial_data[category_names].values\ntest_data[category_names] = test_data[category_names].values\n\n# Set up predictors (/features)\npredictor_names = initial_data.columns.drop([\"Id\", \"SalePrice\", \"SaleType\", \"SaleCondition\"]).values\nX_initial = initial_data[predictor_names]\nX_test = test_data[predictor_names]\n\n# Set up target\ntarget_name = \"SalePrice\"\ny_initial = np.log(initial_data[target_name])\n\n# Split datasets\nX_train, X_validate, y_train, y_validate = train_test_split(X_initial, y_initial, random_state=random_state)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"# Examine data/features\n\nprint(\"Features\")\nprint(predictor_names)\nprint(\"\\n\")\n\nprint(X_train.head())\nprint(X_train.describe())\nprint(\"\\n\")\n\nprint(y_train.head())\nprint(y_train.describe())\nprint(\"\\n\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"238961fc181052852a4060305ba7feeda36d3a8a"},"cell_type":"code","source":"# Build pipeline components\n\nimputer = SimpleImputer()\nencoder = OneHotEncoder()\ncreateEstimator = (lambda params = {}: XGBRegressor(random_state=random_state, **params))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ad76288faeae717d512171f02d30f2a0fa3cc340","_kg_hide-input":false,"scrolled":true},"cell_type":"code","source":"# # Find optimal parameters (only needs running once for each model change)\n\n# fixedParams = {\n#     \"n_estimators\": 550,\n#     \"max_depth\": 3,\n# #     \"early_stopping_rounds\": 1,\n# #     \"learning_rate\": 0.1,\n#     \"eval_set\": [(X_validate, y_validate)],\n# }\n\n# base_pipeline = Pipeline([(\"encoder\", encoder), (\"imputer\", imputer), (\"estimator\", createEstimator(fixedParams))])\n\n# param_grid = {\n# #     \"estimator__n_estimators\": [300, 500, 550, 600, 800],\n#     \"estimator__early_stopping_rounds\": [1, 2, 3],\n#     \"estimator__learning_rate\": [0.08, 0.1, 0.12],\n# #     \"estimator__max_depth\": [1, 3, 5, 10],\n# }\n# grid = GridSearchCV(base_pipeline, param_grid, n_jobs=-1, cv=5)\n# grid.fit(X_train, y_train)\n\n# pipeline = grid.best_estimator_\n\n# print(pipeline.get_params().keys())\n# print(grid.best_score_)\n# print(grid.best_params_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"16e9159bfce529b1d6284291e9d2b2341d07b79d"},"cell_type":"code","source":"# Quick model training (only run once optimal parameters have been found)\n\nparams = {\n    \"n_estimators\": 550,\n    \"max_depth\": 3,\n    \"early_stopping_rounds\": 1,\n    \"learning_rate\": 0.1,\n}\npipeline = Pipeline([(\"encoder\", encoder), (\"imputer\", imputer), (\"estimator\", createEstimator(params))])\npipeline.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5187410f3a5e3013c190570cff0f7ba05cd4185e"},"cell_type":"code","source":"# Analyse\n\npredictions = pipeline.predict(X_validate)\n\nreadable_predictions = np.exp(predictions)\nreadable_y_validate = np.exp(y_validate)\n\nfrom sklearn.metrics import mean_squared_log_error\nrmsle = np.sqrt(mean_squared_log_error(readable_y_validate, readable_predictions))\nprint(\"Root Mean Squared Log Error\")\nprint(rmsle)\nprint(\"\")\n\nprint(\"First 5\")\nprint([float(x) for x in readable_predictions[:5]])\nprint([float(x) for x in readable_y_validate[:5]])\nprint(\"\")\n\nprint(\"Last 5\")\nprint([float(x) for x in readable_predictions[-5:]])\nprint([float(x) for x in readable_y_validate[-5:]])\nprint(\"\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"af9589ed50b5f06e7e6083fe5d010f64bc44ebfc"},"cell_type":"code","source":"# Merge train & validation data for final model\n\nX = pd.concat([X_train, X_validate])\ny = pd.concat([y_train, y_validate])\npipeline.fit(X, y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ddfbe470f3edc4559224ac698edb4b6a8a78de55"},"cell_type":"code","source":"# Submit\ntest_predictions = pipeline.predict(X_test)\nsubmission = pd.DataFrame({'Id': test_data.Id, 'SalePrice': np.exp(test_predictions)})\nsubmission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a1a1b87b099f26ebf9c2d24d6ce14216c9075158"},"cell_type":"markdown","source":"## Notes\n\n* Don't need to manually split CV data with `StratifiedKFold` or similar, it's done automatically by `GridSearchCV` (defaults to 3-fold).\n\n## References\n\n* [GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)\n* [RandomForestRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html)\n* [Mean squared log error](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_log_error.html)"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}